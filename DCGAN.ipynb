{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm.notebook import tqdm\n",
    "!jupyter nbextension enable --py widgetsnbextension\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,in_channel,out_channel ) -> None:\n",
    "        super(Discriminator,self).__init__()\n",
    "        #input: (bs,channel,64,64)\n",
    "        self.discrimator=nn.Sequential(\n",
    "            nn.Conv2d(in_channel,out_channel,kernel_size=4,stride=2,padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            self.block(out_channel,out_channel*2,kernel_size=4,stride=2,padding=1),\n",
    "            self.block(out_channel*2,out_channel*4,kernel_size=4,stride=2,padding=1),\n",
    "            self.block(out_channel*4,out_channel*8,kernel_size=4,stride=2,padding=1),\n",
    "            nn.Conv2d(out_channel*8,1,kernel_size=4,stride=2,padding=0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def block(self,in_channel,out_channel,kernel_size,stride,padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channel,out_channel,kernel_size,stride,padding,bias=False))\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.discrimator(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d=Discriminator(3,1)\n",
    "x=torch.randn(1,3,64,64)\n",
    "d(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self,noise_dim,in_channels,out_channels):\n",
    "        super(Generator, self).__init__()\n",
    "        self.generator=nn.Sequential(\n",
    "            self.block(noise_dim,out_channels*16,kernel_size=4,stride=2,padding=0),\n",
    "            self.block(out_channels*16,out_channels*8,kernel_size=4,stride=2,padding=1),\n",
    "            self.block(out_channels*8,out_channels*4,kernel_size=4,stride=2,padding=1),\n",
    "            self.block(out_channels*4,out_channels*2,kernel_size=4,stride=2,padding=1),\n",
    "            nn.ConvTranspose2d(out_channels*2,in_channels,4,2,1),\n",
    "            nn.Tanh(), #[-1,1]\n",
    "        )\n",
    "    def block(self,in_channel,out_channel,kernel_size,stride,padding):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channel,out_channel,kernel_size,stride,padding),\n",
    "            nn.BatchNorm2d(out_channel),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.generator(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# initalize weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initalize_weight(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m,(nn.Conv2d,nn.ConvTranspose2d,nn.BatchNorm2d)):\n",
    "            nn.init.normal_(m.weight.data,0.0,0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 64, 64])\n",
      "disc model torch.Size([4, 1, 1, 1])\n",
      "torch.Size([4, 100, 1, 1])\n",
      "torch.Size([4, 1, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    noise_dim=100\n",
    "    b,in_channel,h,w=4,1,64,64\n",
    "    x=torch.randn((b,in_channel,h,w))\n",
    "    print(x.shape)\n",
    "    disc=Discriminator(in_channel,8)\n",
    "    initalize_weight(disc)\n",
    "    assert disc(x).shape == (b,1,1,1)\n",
    "    dis_model=disc(x)\n",
    "    print('disc model',dis_model.shape)\n",
    "    gen=Generator(noise_dim,in_channel,8)\n",
    "    y=torch.randn((b,noise_dim,1,1))\n",
    "    print(y.shape)\n",
    "    gen_model=gen(y)\n",
    "    assert gen_model.shape== (b,in_channel,h,w)\n",
    "    print(gen_model.shape)\n",
    "    \n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hyperparameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters etc.\n",
    "CUDA=torch.cuda.is_available()\n",
    "# CUDA=False\n",
    "device = \"cuda:7\" if CUDA else \"cpu\"\n",
    "lr = 1e-5\n",
    "noise_dim = 200\n",
    "batch_size = 128\n",
    "in_channel=3 #1\n",
    "Image_size=64\n",
    "num_epochs=10\n",
    "out_channel_gen=64\n",
    "out_channel_disc=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "    transforms.Resize((Image_size,Image_size)),\n",
    "    # transforms.Resize(Image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        [0.5 for _ in range(in_channel)],\n",
    "        [0.5 for _ in range(in_channel)],  \n",
    "    )\n",
    "])\n",
    "# dataset=datasets.MNIST(root=\"dataset/\",train=True,transform=transform,download=True)\n",
    "dataset=datasets.ImageFolder(root=\"/mnt/disk1/Gulshan/dataset/Dog_data\",transform=transform)\n",
    "loader=DataLoader(dataset,batch_size=batch_size,shuffle=True)\n",
    "generator=Generator(noise_dim,in_channel,out_channel_gen).to(device)\n",
    "discrmintor=Discriminator(in_channel,out_channel_disc).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=next(iter(loader))\n",
    "# x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "initalize_weight(generator)\n",
    "initalize_weight(discrmintor)\n",
    "optimizer_gen=optim.Adam(generator.parameters(),lr=lr,betas=(0.5,0.999))\n",
    "optimizer_disc=optim.Adam(discrmintor.parameters(),lr=lr,betas=(0.5,0.999))\n",
    "criterion=nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_noise=torch.randn(16,noise_dim,1,1).to(device)\n",
    "writer_real=SummaryWriter(\"logs/real\")\n",
    "writer_fake=SummaryWriter(\"logs/fake\")\n",
    "step=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7ee5a7f21e8477aa0d46dfbf426ca8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6984221615d2483faecd86999ea88879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] Batch 0/67                       Loss D: 0.6928, loss G: 0.6723,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0694fdb4e9b24fb6a5469aad52f164b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10] Batch 0/67                       Loss D: 0.1248, loss G: 2.1126,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9f4d33f12894443887c4889bfc13dc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10] Batch 0/67                       Loss D: 0.0385, loss G: 3.7272,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88276ecb7d78460f88080dc936ab1cc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10] Batch 0/67                       Loss D: 0.0103, loss G: 4.5461,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04453554bd62414bbe27fb93efbc511e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10] Batch 0/67                       Loss D: 0.0057, loss G: 4.6806,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a937ac0045504d7ea694e4b468f17ad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10] Batch 0/67                       Loss D: 0.0034, loss G: 5.2882,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a4e995618794363a7fbbe4b83e2d5ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10] Batch 0/67                       Loss D: 0.0064, loss G: 4.5461,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e76821b7725b44008be2aa4ee45d9ffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10] Batch 0/67                       Loss D: 0.0096, loss G: 5.4217,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3738df5cadf482bbb2e810790fb12f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10] Batch 0/67                       Loss D: 0.0091, loss G: 5.5884,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38bbddcaf90c4536b91cdccc39d45a98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10] Batch 0/67                       Loss D: 0.0035, loss G: 5.8262,\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(num_epochs),total=num_epochs):\n",
    "    \n",
    "    running_loss_gen=0\n",
    "    for batch_idx, (real, _) in tqdm(enumerate(loader)):\n",
    "        real=real.to(device)\n",
    "        noise=torch.randn((batch_size,noise_dim,1,1)).to(device)\n",
    "        fake=generator(noise)\n",
    "        ##loss for discrimi\n",
    "        disc_real=discrmintor(real).reshape(-1)\n",
    "        loss_disc_real=criterion(disc_real,torch.ones_like(disc_real))\n",
    "        \n",
    "        disc_fake=discrmintor(fake).reshape(-1)\n",
    "        loss_disc_fake=criterion(disc_fake,torch.zeros_like(disc_fake))\n",
    "        \n",
    "        loss_disc=(loss_disc_real+loss_disc_fake)/2\n",
    "        optimizer_disc.zero_grad()\n",
    "        loss_disc.backward(retain_graph=True)\n",
    "        optimizer_disc.step()\n",
    "        \n",
    "        ## losss for generater\n",
    "        gen_out=discrmintor(fake).reshape(-1)\n",
    "        gen_loss=criterion(gen_out,torch.ones_like(gen_out))\n",
    "        \n",
    "        optimizer_gen.zero_grad()\n",
    "        gen_loss.backward()\n",
    "        optimizer_gen.step()\n",
    "        \n",
    "        running_loss_gen+=gen_loss\n",
    "        \n",
    "        if batch_idx == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch+1}/{num_epochs}] Batch {batch_idx}/{len(loader)} \\\n",
    "                      Loss D: {loss_disc:.4f}, loss G: {gen_loss:.4f},\"\n",
    "            )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                fake = generator(fixed_noise)\n",
    "                img_grid_fake = torchvision.utils.make_grid(fake[:32], normalize=True)\n",
    "                img_grid_real = torchvision.utils.make_grid(real[:32], normalize=True)\n",
    "\n",
    "                writer_fake.add_image(\n",
    "                    \"Mnist Fake Images\", img_grid_fake, global_step=step\n",
    "                )\n",
    "                writer_real.add_image(\n",
    "                    \"Mnist Real Images\", img_grid_real, global_step=step\n",
    "                )\n",
    "                writer_fake.add_scalar(\"Fake loss\",running_loss_gen,global_step=step)\n",
    "                step += 1\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.14.0 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "E0507 15:08:24.187219 139732731819776 _internal.py:96] Error on request:\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/disk1/conda/envs/gulshan/lib/python3.8/site-packages/werkzeug/serving.py\", line 362, in run_wsgi\n",
      "    execute(self.server.app)\n",
      "  File \"/mnt/disk1/conda/envs/gulshan/lib/python3.8/site-packages/werkzeug/serving.py\", line 323, in execute\n",
      "    application_iter = app(environ, start_response)\n",
      "  File \"/mnt/disk1/conda/envs/gulshan/lib/python3.8/site-packages/tensorboard/backend/application.py\", line 528, in __call__\n",
      "    return self._app(environ, start_response)\n",
      "  File \"/mnt/disk1/conda/envs/gulshan/lib/python3.8/site-packages/tensorboard/backend/application.py\", line 569, in wrapper\n",
      "    return wsgi_app(environ, start_response)\n",
      "  File \"/mnt/disk1/conda/envs/gulshan/lib/python3.8/site-packages/tensorboard/backend/security_validator.py\", line 91, in __call__\n",
      "    return self._application(environ, start_response_proxy)\n",
      "  File \"/mnt/disk1/conda/envs/gulshan/lib/python3.8/site-packages/tensorboard/backend/path_prefix.py\", line 68, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/mnt/disk1/conda/envs/gulshan/lib/python3.8/site-packages/tensorboard/backend/experiment_id.py\", line 73, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/mnt/disk1/conda/envs/gulshan/lib/python3.8/site-packages/tensorboard/backend/empty_path_redirect.py\", line 43, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/mnt/disk1/conda/envs/gulshan/lib/python3.8/site-packages/tensorboard/backend/client_feature_flags.py\", line 55, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/mnt/disk1/conda/envs/gulshan/lib/python3.8/site-packages/tensorboard/backend/auth_context_middleware.py\", line 38, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/mnt/disk1/conda/envs/gulshan/lib/python3.8/site-packages/tensorboard/backend/application.py\", line 551, in _route_request\n",
      "    return self.exact_routes[clean_path](environ, start_response)\n",
      "  File \"/mnt/disk1/conda/envs/gulshan/lib/python3.8/site-packages/werkzeug/wrappers/request.py\", line 189, in application\n",
      "    resp = f(*args[:-2] + (request,))\n",
      "  File \"/mnt/disk1/conda/envs/gulshan/lib/python3.8/site-packages/tensorboard/plugins/hparams/hparams_plugin.py\", line 122, in get_experiment_route\n",
      "    json_format.MessageToJson(\n",
      "TypeError: MessageToJson() got an unexpected keyword argument 'including_default_value_fields'\n",
      "E0507 15:08:25.243798 139732530476800 _internal.py:96] Error on request:\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/disk1/conda/envs/gulshan/lib/python3.8/site-packages/werkzeug/serving.py\", line 362, in run_wsgi\n",
      "    execute(self.server.app)\n",
      "  File \"/mnt/disk1/conda/envs/gulshan/lib/python3.8/site-packages/werkzeug/serving.py\", line 323, in execute\n",
      "    application_iter = app(environ, start_response)\n",
      "  File \"/mnt/disk1/conda/envs/gulshan/lib/python3.8/site-packages/tensorboard/backend/application.py\", line 528, in __call__\n",
      "    return self._app(environ, start_response)\n",
      "  File \"/mnt/disk1/conda/envs/gulshan/lib/python3.8/site-packages/tensorboard/backend/application.py\", line 569, in wrapper\n",
      "    return wsgi_app(environ, start_response)\n",
      "  File \"/mnt/disk1/conda/envs/gulshan/lib/python3.8/site-packages/tensorboard/backend/security_validator.py\", line 91, in __call__\n",
      "    return self._application(environ, start_response_proxy)\n",
      "  File \"/mnt/disk1/conda/envs/gulshan/lib/python3.8/site-packages/tensorboard/backend/path_prefix.py\", line 68, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/mnt/disk1/conda/envs/gulshan/lib/python3.8/site-packages/tensorboard/backend/experiment_id.py\", line 73, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/mnt/disk1/conda/envs/gulshan/lib/python3.8/site-packages/tensorboard/backend/empty_path_redirect.py\", line 43, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/mnt/disk1/conda/envs/gulshan/lib/python3.8/site-packages/tensorboard/backend/client_feature_flags.py\", line 55, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/mnt/disk1/conda/envs/gulshan/lib/python3.8/site-packages/tensorboard/backend/auth_context_middleware.py\", line 38, in __call__\n",
      "    return self._application(environ, start_response)\n",
      "  File \"/mnt/disk1/conda/envs/gulshan/lib/python3.8/site-packages/tensorboard/backend/application.py\", line 551, in _route_request\n",
      "    return self.exact_routes[clean_path](environ, start_response)\n",
      "  File \"/mnt/disk1/conda/envs/gulshan/lib/python3.8/site-packages/werkzeug/wrappers/request.py\", line 189, in application\n",
      "    resp = f(*args[:-2] + (request,))\n",
      "  File \"/mnt/disk1/conda/envs/gulshan/lib/python3.8/site-packages/tensorboard/plugins/hparams/hparams_plugin.py\", line 122, in get_experiment_route\n",
      "    json_format.MessageToJson(\n",
      "TypeError: MessageToJson() got an unexpected keyword argument 'including_default_value_fields'\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# ! tensorboard --logdir=/mnt/disk1/Gulshan/GAN/DCGAN/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gulshan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
