{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\n",
      "      - Validating: \u001b[32mOK\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from tqdm.notebook import tqdm\n",
    "!jupyter nbextension enable --py widgetsnbextension\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,in_channels,features=[64,128,256,512],) -> None:\n",
    "        super(Discriminator,self).__init__()\n",
    "        # in channeel *2 because we concate the label and image channel(3+3=6)\n",
    "        \n",
    "        self.con1=nn.Conv2d(in_channels*2,features[0],kernel_size=4,\n",
    "                            stride=2,padding=1,padding_mode=\"reflect\")\n",
    "        self.con2=nn.Conv2d(features[0],features[1],kernel_size=4,stride=2,bias=False,\n",
    "                            padding=1,padding_mode=\"reflect\")\n",
    "        self.con3=nn.Conv2d(features[1],features[2],kernel_size=4,stride=2,bias=False,\n",
    "                            padding=1,padding_mode=\"reflect\")\n",
    "        self.con4=nn.Conv2d(features[2],features[3],kernel_size=4,stride=1,bias=False,\n",
    "                            padding=1,padding_mode=\"reflect\")\n",
    "        self.last_conv=nn.Conv2d(features[3],1,kernel_size=4,\n",
    "                                 stride=1,padding=1,padding_mode='reflect')\n",
    "        \n",
    "        self.leaky=nn.LeakyReLU(0.2)\n",
    "        self.batchNorm2=nn.BatchNorm2d(features[1])\n",
    "        self.batchNorm3=nn.BatchNorm2d(features[2])\n",
    "        self.batchNorm4=nn.BatchNorm2d(features[3])\n",
    "        \n",
    "    def forward(self,image,label):\n",
    "        # print(image.shape) # torch.Size([1, 3, 256, 256])\n",
    "        # print(label.shape) #torch.Size([1, 3, 256, 256])\n",
    "        out=torch.cat([image,label],dim=1)\n",
    "        # print(out.shape)# torch.Size([1, 6, 256, 256])\n",
    "        \n",
    "        out=self.con1(out)\n",
    "        # print(out.shape)#torch.Size([1, 64, 128, 128])\n",
    "        out=self.leaky(out)\n",
    "        \n",
    "        out=self.con2(out)\n",
    "        # print(out.shape)#torch.Size([1, 128, 64, 64])\n",
    "        out=self.batchNorm2(out)\n",
    "        out=self.leaky(out)\n",
    "        \n",
    "        out=self.con3(out)\n",
    "        # print(out.shape)#torch.Size([1, 256, 32, 32])\n",
    "        out=self.batchNorm3(out)\n",
    "        out=self.leaky(out)\n",
    "        \n",
    "        out=self.con4(out)\n",
    "        # print(out.shape)#torch.Size([1, 512, 31, 31])\n",
    "        out=self.batchNorm4(out)\n",
    "        out=self.leaky(out)\n",
    "        \n",
    "        out=self.last_conv(out)\n",
    "        # print(out.shape)#torch.Size([1, 1, 30, 30])\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "x=torch.randn((1,3,256,256))\n",
    "y=torch.randn((1,3,256,256))\n",
    "model=Discriminator(in_channels=3)\n",
    "out=model(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self,in_channels=3,features=64) -> None:\n",
    "        super(Generator,self).__init__()\n",
    "        self.d1=nn.Conv2d(in_channels,features,kernel_size=4,\n",
    "                             stride=2,padding=1,padding_mode=\"reflect\")\n",
    "        \n",
    "        self.d2=nn.Conv2d(features,features*2,4,2,1,padding_mode='reflect',bias=False)\n",
    "        self.batch_norm_d2=nn.BatchNorm2d(features*2)\n",
    "        \n",
    "        self.d3=nn.Conv2d(features*2,features*4,4,2,1,padding_mode='reflect',bias=False)\n",
    "        self.batch_norm_d3=nn.BatchNorm2d(features*4)\n",
    "        \n",
    "        self.d4=nn.Conv2d(features*4,features*8,4,2,1,padding_mode='reflect',bias=False)\n",
    "        self.batch_norm_d4=nn.BatchNorm2d(features*8)\n",
    "        \n",
    "        self.d5=nn.Conv2d(features*8,features*8,4,2,1,padding_mode='reflect',bias=False)\n",
    "        self.batch_norm_d5=nn.BatchNorm2d(features*8)\n",
    "        \n",
    "        self.d6=nn.Conv2d(features*8,features*8,4,2,1,padding_mode='reflect',bias=False)\n",
    "        self.batch_norm_d6=nn.BatchNorm2d(features*8)\n",
    "        \n",
    "        self.d7=nn.Conv2d(features*8,features*8,4,2,1,padding_mode='reflect',bias=False)\n",
    "        self.batch_norm_d7=nn.BatchNorm2d(features*8)\n",
    "        \n",
    "        self.u1=nn.ConvTranspose2d(features*8,features*8,4,2,1,bias=False)\n",
    "        self.batch_norm_u1=nn.BatchNorm2d(features*8)\n",
    "        \n",
    "        self.u2=nn.ConvTranspose2d(features*8*2,features*8,4,2,1,bias=False)\n",
    "        self.batch_norm_u2=nn.BatchNorm2d(features*8)\n",
    "        \n",
    "        self.u3=nn.ConvTranspose2d(features*8*2,features*8,4,2,1,bias=False)\n",
    "        self.batch_norm_u3=nn.BatchNorm2d(features*8)\n",
    "        \n",
    "        self.u4=nn.ConvTranspose2d(features*8*2,features*8,4,2,1,bias=False)\n",
    "        self.batch_norm_u4=nn.BatchNorm2d(features*8)\n",
    "        \n",
    "        self.u5=nn.ConvTranspose2d(features*8*2,features*4,4,2,1,bias=False)\n",
    "        self.batch_norm_u5=nn.BatchNorm2d(features*4)\n",
    "        \n",
    "        self.u6=nn.ConvTranspose2d(features*4*2,features*2,4,2,1,bias=False)\n",
    "        self.batch_norm_u6=nn.BatchNorm2d(features*2)\n",
    "        \n",
    "        self.u7=nn.ConvTranspose2d(features*2*2,features,4,2,1,bias=False)\n",
    "        self.batch_norm_u7=nn.BatchNorm2d(features)\n",
    "        \n",
    "        self.final_layer=nn.ConvTranspose2d(features*2,in_channels,4,2,1)\n",
    "        \n",
    "        self.bottleneck=nn.Conv2d(features*8,features*8,4,2,1,bias=False)\n",
    "        self.leaky=nn.LeakyReLU(0.2)\n",
    "        self.dropout=nn.Dropout(0.5)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.tanh=nn.Tanh()\n",
    "        \n",
    "    def forward(self,image):\n",
    "        # print(image.shape) #torch.Size([1, 3, 256, 256])\n",
    "        d1=self.d1(image)\n",
    "        d1=self.leaky(d1)\n",
    "        # print(d1.shape) # torch.Size([1, 64, 128, 128])\n",
    "        d2=self.d2(d1)\n",
    "        d2=self.batch_norm_d2(d2)\n",
    "        d2=self.leaky(d2)\n",
    "        # print(d2.shape)#torch.Size([1, 128, 64, 64])\n",
    "        d3=self.d3(d2)\n",
    "        d3=self.batch_norm_d3(d3)\n",
    "        d3=self.leaky(d3)\n",
    "        # print(d3.shape)#torch.Size([1, 256, 32, 32])\n",
    "        \n",
    "        d4=self.d4(d3)\n",
    "        d4=self.batch_norm_d4(d4)\n",
    "        d4=self.leaky(d4)\n",
    "        # print(d4.shape)#torch.Size([1, 512, 16, 16])\n",
    "        \n",
    "        d5=self.d5(d4)\n",
    "        d5=self.batch_norm_d5(d5)\n",
    "        d5=self.leaky(d5)\n",
    "        # print(d5.shape)#torch.Size([1, 512, 8, 8])\n",
    "        \n",
    "        d6=self.d6(d5)\n",
    "        d6=self.batch_norm_d6(d6)\n",
    "        d6=self.leaky(d6)\n",
    "        # print(d6.shape)#torch.Size([1, 512, 4, 4])\n",
    "        \n",
    "        d7=self.d7(d6)\n",
    "        d7=self.batch_norm_d7(d7)\n",
    "        d7=self.leaky(d7)\n",
    "        # print(d7.shape)#torch.Size([1, 512, 2, 2])\n",
    "        \n",
    "        bn=self.bottleneck(d7)\n",
    "        bn=self.relu(bn)\n",
    "        # print(bn.shape) #torch.Size([1, 512, 1, 1])\n",
    "        \n",
    "        u1=self.u1(bn)\n",
    "        u1=self.batch_norm_u1(u1)\n",
    "        u1=self.relu(u1)\n",
    "        u1=self.dropout(u1)\n",
    "        # print(u1.shape) #torch.Size([1, 512, 2, 2])\n",
    "        \n",
    "        u2=self.u2(torch.cat([u1,d7],1))\n",
    "        u2=self.batch_norm_u2(u2)\n",
    "        u2=self.relu(u2)\n",
    "        u2=self.dropout(u2)\n",
    "        # print(u2.shape) #torch.Size([1, 512, 4, 4])\n",
    "        \n",
    "        u3=self.u3(torch.cat([u2,d6],1))\n",
    "        u3=self.batch_norm_u3(u3)\n",
    "        u3=self.relu(u3)\n",
    "        u3=self.dropout(u3)\n",
    "        # print(u3.shape) #torch.Size([1, 512, 8, 8])\n",
    "        \n",
    "        u4=self.u4(torch.cat([u3,d5],1))\n",
    "        u4=self.batch_norm_u4(u4)\n",
    "        u4=self.relu(u4)\n",
    "        # print(u4.shape) #torch.Size([1, 512, 16, 16])\n",
    "        \n",
    "        u5=self.u5(torch.cat([u4,d4],1))\n",
    "        u5=self.batch_norm_u5(u5)\n",
    "        u5=self.relu(u5)\n",
    "        # print(u5.shape) #torch.Size([1, 256, 32, 32])\n",
    "        \n",
    "        u6=self.u6(torch.cat([u5,d3],1))\n",
    "        u6=self.batch_norm_u6(u6)\n",
    "        u6=self.relu(u6)\n",
    "        # print(u6.shape) #torch.Size([1, 128, 64, 64])\n",
    "        \n",
    "        u7=self.u7(torch.cat([u6,d2],1))\n",
    "        u7=self.batch_norm_u7(u7)\n",
    "        u7=self.relu(u7)\n",
    "        # print(u7.shape) #torch.Size([1, 64, 128, 128])\n",
    "        \n",
    "        out=self.final_layer(torch.cat([u7,d1],1))\n",
    "        out=self.tanh(out)\n",
    "        # print(out.shape) #torch.Size([1, 3, 256, 256])\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# x = torch.randn((1, 3, 256, 256))\n",
    "# model = Generator(in_channels=3, features=64)\n",
    "# preds = model(x)\n",
    "# print(preds.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "tranforms_for_both=A.Compose(\n",
    "    [A.Resize(width=256,height=256)],\n",
    "    additional_targets={\"image0\":\"image\"},) \n",
    "\n",
    "tranform_input=A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.ColorJitter(p=0.2),\n",
    "    A.Normalize(mean=[0.5 for _ in range(3)],\n",
    "                std=[0.5 for _ in range(3)],\n",
    "                max_pixel_value=255.0,),\n",
    "    ToTensorV2()\n",
    "])\n",
    "tranform_mask=A.Compose([\n",
    "    A.Normalize(mean=[0.5 for _ in range(3)],\n",
    "                std=[0.5 for _ in range(3)],\n",
    "                max_pixel_value=255.0,),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# both_transform = A.Compose(\n",
    "#     [A.Resize(width=256, height=256),], additional_targets={\"image0\": \"image\"},\n",
    "# )\n",
    "\n",
    "# transform_only_input = A.Compose(\n",
    "#     [\n",
    "#         A.HorizontalFlip(p=0.5),\n",
    "#         A.ColorJitter(p=0.2),\n",
    "#         A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], max_pixel_value=255.0,),\n",
    "#         ToTensorV2(),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# transform_only_mask = A.Compose(\n",
    "#     [\n",
    "#         A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5], max_pixel_value=255.0,),\n",
    "#         ToTensorV2(),\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "class pix2pixDataset(nn.Module):\n",
    "    def __init__(self,path) -> None:\n",
    "        super(pix2pixDataset,self).__init__()\n",
    "        self.path=path \n",
    "        self.files_list=os.listdir(self.path)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files_list)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        img_file=self.files_list[idx]\n",
    "        image=np.array(Image.open(os.path.join(self.path,img_file)))\n",
    "        H,W,C=image.shape\n",
    "        \n",
    "        input_image=image[:,:W//2,:]\n",
    "        target_image=image[:,W//2:,:]\n",
    "        both_augumentation=tranforms_for_both(image=input_image,image0=target_image)\n",
    "        input_image=both_augumentation[\"image\"]\n",
    "        target_image=both_augumentation[\"image0\"]\n",
    "        \n",
    "        input_image=tranform_input(image=input_image)[\"image\"]\n",
    "        target_image=tranform_mask(image=target_image)[\"image\"]\n",
    "        \n",
    "        # augmentations = both_transform(image=input_image, image0=target_image)\n",
    "        # input_image = augmentations[\"image\"]\n",
    "        # target_image = augmentations[\"image0\"]\n",
    "\n",
    "        # input_image = transform_only_input(image=input_image)[\"image\"]\n",
    "        # target_image = transform_only_mask(image=target_image)[\"image\"]\n",
    "        \n",
    "        return input_image,target_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# d=pix2pixDataset(\"/mnt/disk1/Gulshan/GAN/pix2pix/edges2shoes/val\")\n",
    "# loader = DataLoader(d, batch_size=2)\n",
    "# x,y=next(iter(loader))\n",
    "# print(x.shape,y.shape)\n",
    "# x,y=np.array(x),np.array(y)\n",
    "# x=x.transpose(0,2,3,1)\n",
    "# y=y.transpose(0,2,3,1)\n",
    "# plt.axis('off')\n",
    "# plt.imshow(x[1,...])\n",
    "# plt.show()\n",
    "# plt.axis('off')\n",
    "# plt.imshow(y[1,...])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model intialazing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10992"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device=\"cuda:7\" if torch.cuda.is_available() else \"cpu\"\n",
    "lr=1e-5\n",
    "bs=16\n",
    "num_workers=2\n",
    "num_epochs=30\n",
    "L1_LAMBDA = 100\n",
    "LAMBDA_GP = 10\n",
    "Image_size=256\n",
    "disc=Discriminator(3).to(device)\n",
    "gen=Generator(3).to(device)\n",
    "opt_disc=torch.optim.Adam(disc.parameters(),lr=lr,betas=(0.5,0.999))\n",
    "opt_gen=torch.optim.Adam(gen.parameters(),lr=lr,betas=(0.5,0.999))\n",
    "criterion_BCE=nn.BCEWithLogitsLoss()\n",
    "criterion_L1=nn.L1Loss()\n",
    "train_dataset=pix2pixDataset(\"/mnt/disk1/Gulshan/GAN/pix2pix/edges2shoes/train\")\n",
    "train_loader=DataLoader(train_dataset,batch_size=bs,shuffle=True,num_workers=num_workers,drop_last=True)\n",
    "val_dataset=pix2pixDataset(\"/mnt/disk1/Gulshan/GAN/pix2pix/edges2shoes/val\")\n",
    "val_loader=DataLoader(val_dataset,batch_size=bs,shuffle=False,num_workers=num_workers,drop_last=True)\n",
    "gen_scaler=torch.cuda.amp.GradScaler() # for less v ram usage and train faster\n",
    "disc_scaler=torch.cuda.amp.GradScaler()\n",
    "writer_real = SummaryWriter(f\"logs_pix2pix_{lr}/real\")\n",
    "writer_fake = SummaryWriter(f\"logs_pix2pix_{lr}/fake\")\n",
    "len(train_loader)*bs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21113964acb244e091891fb1891e8ad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a0666e0288d44d99dfc83f7ace8d1ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/687 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687 10992\n",
      "Epoch [1/30] Batch 686/687                   Loss D: 0.0786, loss G: 23.6000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06d95dede004443ca03be91986a0a095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/687 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687 10992\n",
      "Epoch [2/30] Batch 686/687                   Loss D: 0.0404, loss G: 17.9223\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8a2c05b27d34f2fafb6e857ddfb37c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/687 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687 10992\n",
      "Epoch [3/30] Batch 686/687                   Loss D: 0.0152, loss G: 19.7028\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e11bcdeeaaa64b9aa4147ef0b8570bfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/687 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687 10992\n",
      "Epoch [4/30] Batch 686/687                   Loss D: 0.0119, loss G: 17.6959\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "819ebcf4764a4644ac7531f3ce4fc5c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/687 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687 10992\n",
      "Epoch [5/30] Batch 686/687                   Loss D: 0.0061, loss G: 15.8374\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "373660eff5b44cd8a3472c9cad2d55af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/687 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687 10992\n",
      "Epoch [6/30] Batch 686/687                   Loss D: 0.0055, loss G: 13.8820\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7e137e3bad44310ac8fac026f880fc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/687 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687 10992\n",
      "Epoch [7/30] Batch 686/687                   Loss D: 0.0076, loss G: 16.6029\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eac04681d024b0cbcb399f68949324f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/687 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687 10992\n",
      "Epoch [8/30] Batch 686/687                   Loss D: 0.0026, loss G: 17.2765\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4336459c03794f78b40646a2e5953f34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/687 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687 10992\n",
      "Epoch [9/30] Batch 686/687                   Loss D: 0.0036, loss G: 12.8073\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbade1b9c034424bbdfe65e3ad0b77dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/687 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687 10992\n",
      "Epoch [10/30] Batch 686/687                   Loss D: 0.0011, loss G: 13.7405\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4181cdbc4ed742edaf0113e850bc8149",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/687 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687 10992\n",
      "Epoch [11/30] Batch 686/687                   Loss D: 0.0048, loss G: 14.7356\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eae2a26430f49eca6d4ac649f328682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/687 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687 10992\n",
      "Epoch [12/30] Batch 686/687                   Loss D: 0.0123, loss G: 14.5038\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a39823a7fcb54683b517ef36707a7826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/687 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687 10992\n",
      "Epoch [13/30] Batch 686/687                   Loss D: 0.0045, loss G: 12.4705\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17ea43cb6b1343d28f0f2405b26335fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/687 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687 10992\n",
      "Epoch [14/30] Batch 686/687                   Loss D: 0.0009, loss G: 15.6292\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6282e02de644c799b30bed50c84444a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/687 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687 10992\n",
      "Epoch [15/30] Batch 686/687                   Loss D: 0.0034, loss G: 10.7269\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1688b984a14e42c0ac48a881444eec6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/687 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687 10992\n",
      "Epoch [16/30] Batch 686/687                   Loss D: 0.0013, loss G: 14.7663\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa1e2e6f17db42b6bc0c1958a1c89e03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/687 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687 10992\n",
      "Epoch [17/30] Batch 686/687                   Loss D: 0.0020, loss G: 11.5292\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe9f62d32a0447019a0ea75e0593a85e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/687 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687 10992\n",
      "Epoch [18/30] Batch 686/687                   Loss D: 0.0003, loss G: 12.1059\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94002acb54b74be386c824a0dbafe8ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/687 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687 10992\n",
      "Epoch [19/30] Batch 686/687                   Loss D: 0.0005, loss G: 13.0784\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfe821e889c34d7489b136d244e4b59e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/687 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687 10992\n",
      "Epoch [20/30] Batch 686/687                   Loss D: 0.0003, loss G: 10.3417\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77a038a56a9a4acca8b3e72a00cc15dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/687 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687 10992\n",
      "Epoch [21/30] Batch 686/687                   Loss D: 0.0037, loss G: 11.6807\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0fee486ef1a4a1291586280c6be13eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/687 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687 10992\n",
      "Epoch [22/30] Batch 686/687                   Loss D: 0.0216, loss G: 10.1379\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99e292972c214adaae7b182c1e912e15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/687 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687 10992\n",
      "Epoch [23/30] Batch 686/687                   Loss D: 0.0005, loss G: 10.9732\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54516691774a4fbe855775d98a0e7b9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/687 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687 10992\n",
      "Epoch [24/30] Batch 686/687                   Loss D: 0.0003, loss G: 11.5566\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "802db8182b4d4ee6930a2095f57267b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/687 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687 10992\n",
      "Epoch [25/30] Batch 686/687                   Loss D: 0.0001, loss G: 11.5251\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cb950516b954d019c368189afb6c655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/687 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687 10992\n",
      "Epoch [26/30] Batch 686/687                   Loss D: 0.0013, loss G: 10.5489\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "160125f627cd4d5db3ed4e44a524755f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/687 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687 10992\n",
      "Epoch [27/30] Batch 686/687                   Loss D: 0.0007, loss G: 10.3884\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cc553ccdcb04a3f93e01f83bedfcdce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/687 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687 10992\n",
      "Epoch [28/30] Batch 686/687                   Loss D: 0.0005, loss G: 9.8253\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc68a6bb10a54d12848bdc9304749b0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/687 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687 10992\n",
      "Epoch [29/30] Batch 686/687                   Loss D: 0.0007, loss G: 12.8724\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c956b08b28e4dde88076ae6982d73fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/687 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687 10992\n",
      "Epoch [30/30] Batch 686/687                   Loss D: 0.0004, loss G: 12.3877\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    gen.train()\n",
    "    disc.train()\n",
    "    for epoch in tqdm(range(num_epochs),total=num_epochs):\n",
    "        total_disc=0\n",
    "        total_gen=0\n",
    "        for batch_idx,(image,label) in enumerate(tqdm(train_loader)):\n",
    "            image=image.to(device)\n",
    "            label=label.to(device)\n",
    "            # training dicriminator\n",
    "            with torch.cuda.amp.autocast():\n",
    "                fake=gen(image)\n",
    "                d_real=disc(image,label)\n",
    "                d_real_loss = criterion_BCE(d_real, torch.ones_like(d_real))\n",
    "                d_fake=disc(image,fake.detach()) # to retain graph or we can do reatin graph in  loss.backward\n",
    "                d_fake_loss=criterion_BCE(d_fake,torch.zeros_like(d_fake))\n",
    "                d_loss=(d_fake_loss+d_real_loss)/2\n",
    "            opt_disc.zero_grad()\n",
    "            disc_scaler.scale(d_loss).backward()\n",
    "            disc_scaler.step(opt_disc)\n",
    "            disc_scaler.update()\n",
    "            # training generater\n",
    "            with torch.cuda.amp.autocast():\n",
    "                d_fake=disc(image,label)\n",
    "                g_fake_loss=criterion_BCE(d_fake,torch.ones_like(d_fake))\n",
    "                l1_loss=criterion_L1(fake,label)*L1_LAMBDA\n",
    "                g_loss=l1_loss+g_fake_loss\n",
    "            opt_gen.zero_grad()\n",
    "            gen_scaler.scale(g_loss).backward()\n",
    "            gen_scaler.step(opt_gen)\n",
    "            gen_scaler.update()\n",
    "            \n",
    "            total_disc+=image.shape[0]\n",
    "            total_gen+=image.shape[0]\n",
    "            # print(total_gen)\n",
    "            if (len(train_loader)*bs)==total_gen:\n",
    "                print(len(train_loader),total_gen)\n",
    "                print(\n",
    "                f\"Epoch [{epoch+1}/{num_epochs}] Batch {batch_idx}/{len(train_loader)} \\\n",
    "                  Loss D: {d_loss:.4f}, loss G: {g_loss:.4f}\"\n",
    "            )   \n",
    "                with torch.no_grad():\n",
    "                    gen.eval()\n",
    "                    image,label=next(iter(val_loader))\n",
    "                    image,label=image.to(device),label.to(device)\n",
    "                    fake = gen(image)\n",
    "                    # take out (up to) 32 examples\n",
    "                    img_grid_real = torchvision.utils.make_grid(image[:8], normalize=True)\n",
    "                    img_grid_fake = torchvision.utils.make_grid(fake[:8], normalize=True)\n",
    "                    img_grid_label = torchvision.utils.make_grid(label[:8], normalize=True)\n",
    "\n",
    "                    # writer_real.add_image(\"Real\", img_grid_real, global_step=step)\n",
    "                    writer_real.add_image(\"Fake\", img_grid_label, global_step=epoch+1)\n",
    "                    writer_real.add_image(\"Real\", img_grid_real, global_step=epoch+1)\n",
    "                    writer_fake.add_image(\"Fake\", img_grid_fake, global_step=epoch+1)\n",
    "                    writer_fake.add_scalar(\"Fake loss\",g_loss/total_gen,global_step=epoch+1)\n",
    "                    writer_real.add_scalar(\"discrimitor loss\",d_loss/total_disc,global_step=epoch+1)\n",
    "                gen.train()\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gulshan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
